"use strict";(self.webpackChunkcloud_platform_documentation=self.webpackChunkcloud_platform_documentation||[]).push([[346],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>f});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),s=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=s(e.components);return r.createElement(l.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),m=s(n),d=o,f=m["".concat(l,".").concat(d)]||m[d]||u[d]||a;return n?r.createElement(f,i(i({ref:t},c),{},{components:n})):r.createElement(f,i({ref:t},c))}));function f(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=d;var p={};for(var l in t)hasOwnProperty.call(t,l)&&(p[l]=t[l]);p.originalType=e,p[m]="string"==typeof e?e:o,i[1]=p;for(var s=2;s<a;s++)i[s]=n[s];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},9859:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>p,toc:()=>s});var r=n(7462),o=(n(7294),n(3905));const a={},i="\u63a8\u7406API\u4f7f\u7528: \u5229\u7528 Triton \u63a8\u7406\u670d\u52a1\u5668 \u90e8\u7f72 TensorRT \u6a21\u578b",p={unversionedId:"blog/inference_api_tensorrt_triton/README",id:"blog/inference_api_tensorrt_triton/README",title:"\u63a8\u7406API\u4f7f\u7528: \u5229\u7528 Triton \u63a8\u7406\u670d\u52a1\u5668 \u90e8\u7f72 TensorRT \u6a21\u578b",description:"TensorRT\u662f\u4e00\u4e2a\u6709\u52a9\u4e8e\u5728NVIDIA\u56fe\u5f62\u5904\u7406\u5355\u5143\uff08GPU\uff09\u4e0a\u9ad8\u6027\u80fd\u63a8\u7406c++\u5e93\u3002\u5b83\u65e8\u5728\u4e0eTesnsorFlow\u3001Caffe\u3001Pytorch\u4ee5\u53caMXNet\u7b49\u8bad\u7ec3\u6846\u67b6\u4ee5\u4e92\u8865\u7684\u65b9\u5f0f\u8fdb\u884c\u5de5\u4f5c\uff0c\u4e13\u95e8\u81f4\u529b\u4e8e\u5728GPU\u4e0a\u5feb\u901f\u6709\u6548\u5730\u8fdb\u884c\u7f51\u7edc\u63a8\u7406\u3002",source:"@site/docs/blog/inference_api_tensorrt_triton/README.md",sourceDirName:"blog/inference_api_tensorrt_triton",slug:"/blog/inference_api_tensorrt_triton/",permalink:"/docs/blog/inference_api_tensorrt_triton/",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/blog/inference_api_tensorrt_triton/README.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"\u63a8\u7406API \u4f7f\u7528: \u5229\u7528vLLM\u90e8\u7f72 Llama-2-70b-hf \u63a8\u7406\u670d\u52a1",permalink:"/docs/blog/inference_api_llama2_70b_vllm/"}},l={},s=[{value:"\u8fd0\u884c\u73af\u5883\u8981\u6c42",id:"\u8fd0\u884c\u73af\u5883\u8981\u6c42",level:2},{value:"1. \u51c6\u5907TensorRT\u6a21\u578b",id:"1-\u51c6\u5907tensorrt\u6a21\u578b",level:2},{value:"2. \u542f\u52a8\u63a8\u7406API",id:"2-\u542f\u52a8\u63a8\u7406api",level:2},{value:"3. \u6d4b\u8bd5\u63a8\u7406API",id:"3-\u6d4b\u8bd5\u63a8\u7406api",level:2}],c={toc:s},m="wrapper";function u(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,r.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"\u63a8\u7406api\u4f7f\u7528-\u5229\u7528-triton-\u63a8\u7406\u670d\u52a1\u5668-\u90e8\u7f72-tensorrt-\u6a21\u578b"},"\u63a8\u7406API\u4f7f\u7528: \u5229\u7528 Triton \u63a8\u7406\u670d\u52a1\u5668 \u90e8\u7f72 TensorRT \u6a21\u578b"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/TensorRT"},"TensorRT"),"\u662f\u4e00\u4e2a\u6709\u52a9\u4e8e\u5728NVIDIA\u56fe\u5f62\u5904\u7406\u5355\u5143\uff08GPU\uff09\u4e0a\u9ad8\u6027\u80fd\u63a8\u7406c++\u5e93\u3002\u5b83\u65e8\u5728\u4e0eTesnsorFlow\u3001Caffe\u3001Pytorch\u4ee5\u53caMXNet\u7b49\u8bad\u7ec3\u6846\u67b6\u4ee5\u4e92\u8865\u7684\u65b9\u5f0f\u8fdb\u884c\u5de5\u4f5c\uff0c\u4e13\u95e8\u81f4\u529b\u4e8e\u5728GPU\u4e0a\u5feb\u901f\u6709\u6548\u5730\u8fdb\u884c\u7f51\u7edc\u63a8\u7406\u3002"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/triton-inference-server/server"},"Triton\u63a8\u7406\u670d\u52a1\u5668"),"\u662f\u4e00\u79cd\u5f00\u6e90\u63a8\u7406\u670d\u52a1\u8f6f\u4ef6\uff0c\u53ef\u4ee5\u7b80\u5316AI\u63a8\u7406\u3002Triton\u4f7f\u56e2\u961f\u80fd\u591f\u4ece\u591a\u4e2a\u6df1\u5ea6\u5b66\u4e60\u548c\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff08\u5305\u62ecTensorRT\u3001TensorFlow\u3001PyTorch\u3001ONNX\u3001OpenVINO\u3001Python\u3001RAPIDS FIL\u7b49\uff09\u90e8\u7f72\u4efb\u4f55AI\u6a21\u578b\u3002"),(0,o.kt)("p",null,"\u8fd9\u4e2a\u5feb\u901f\u5165\u95e8\u6307\u5357\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528 Colossal-AI \u4e91\u5e73\u53f0\u5728 Triton \u63a8\u7406\u670d\u52a1\u5668\u4e0a\u4f7f\u7528 TensorRT \u52a0\u901f\u90e8\u7f72\u4e00\u4e2a\u7b80\u5355\u7684 DenseNet \u6a21\u578b\u3002\u8ba9\u6211\u4eec\u9010\u6b65\u8ba8\u8bba\u5982\u4f55\u5728\u4e91\u5e73\u53f0\u4e0a\u4f7f\u7528 TensorRT \u4f18\u5316\u6a21\u578b\u3001\u5728 Triton \u63a8\u7406\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\u5b83\uff0c\u5e76\u6784\u5efa\u4e00\u4e2a\u5ba2\u6237\u7aef\u6765\u67e5\u8be2\u8be5\u6a21\u578b\u7684\u8fc7\u7a0b\u3002"),(0,o.kt)("p",null,"Tags: \xa0\u63a8\u7406API\uff0cTensorRT\uff0cTriton Server"),(0,o.kt)("h2",{id:"\u8fd0\u884c\u73af\u5883\u8981\u6c42"},"\u8fd0\u884c\u73af\u5883\u8981\u6c42"),(0,o.kt)("p",null,"\u955c\u50cf\uff1a\u63a8\u8350\u4f7f\u7528\u5b98\u65b9\u955c\u50cf triton-server-24.1"),(0,o.kt)("p",null,"GPU\u89c4\u683c\uff1a\u63a8\u8350\u4f7f\u7528H800 \uff081\u5757\uff09"),(0,o.kt)("h2",{id:"1-\u51c6\u5907tensorrt\u6a21\u578b"},"1. \u51c6\u5907TensorRT\u6a21\u578b"),(0,o.kt)("p",null,"\u53ef\u4f7f\u7528\u4e91\u5e73\u53f0\u5185\u7f6e\u7684 DenseNet TensorRT \u6a21\u578b\uff0c\u6216\u4ece ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/TensorRT/tree/main/quickstart/deploy_to_triton#step-1-optimize-your-model-with-tensorrt"},"Triton Server TensorRT Conversion")," \u4e2d\u6309\u6b65\u9aa4\u8f6c\u6362\u83b7\u5f97TensorRT \u6a21\u578b\uff0c\u5e76\u4e0a\u4f20\u5230 Colossal-AI \u4e91\u5e73\u53f0\u3002"),(0,o.kt)("h2",{id:"2-\u542f\u52a8\u63a8\u7406api"},"2. \u542f\u52a8\u63a8\u7406API"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u5728\u63a7\u5236\u53f0\u4e2d\u9009\u62e9",(0,o.kt)("inlineCode",{parentName:"p"},"\u63a8\u7406API"),"\u9009\u9879\uff0c\u70b9\u51fb ",(0,o.kt)("inlineCode",{parentName:"p"},"\u521b\u5efa\u65b0\u7684API"),"\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u586b\u5199\u5bf9\u5e94\u7684API\u540d\u79f0\u548c\u63cf\u8ff0\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u6302\u8f7d\u6587\u4ef6\uff1a\u5c06\u4e4b\u524d\u51c6\u5907\u597d\u7684 DenseNet TensorRT \u6a21\u578b\u6302\u8f7d\u5230 Container \u4e2d\uff0c\u5728\u8fd9\u4e2a\u4f8b\u5b50\u91cc\uff0c\u6a21\u578b\u88ab\u6302\u8f7d\u5230\u4e86 ",(0,o.kt)("inlineCode",{parentName:"p"},"/mnt/model/densenet_tensorrt"),"\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u542f\u52a8\u547d\u4ee4\uff1a\u586b\u5165 ",(0,o.kt)("inlineCode",{parentName:"p"},"tritonserver --model-repository=/mnt/model --http-port 8080"),"\uff0c\u5728\u8fd9\u884c\u547d\u4ee4\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e861\u5757 GPU \u90e8\u7f72 Triton \u7684\u63a8\u7406API\u670d\u52a1\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u955c\u50cf\u8bbe\u7f6e\uff1a\u9009\u62e9\u5b98\u65b9\u955c\u50cf ",(0,o.kt)("inlineCode",{parentName:"p"},"triton-server"),"\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u663e\u5361\u914d\u7f6e\uff1a\u63a8\u8350\u9009\u62e9 ",(0,o.kt)("inlineCode",{parentName:"p"},"NVIDA-H800"),"\uff0c\u6bcf\u4e2a\u526f\u672c GPU \u6570\u91cf\u8bbe\u7f6e\u4e3a ",(0,o.kt)("inlineCode",{parentName:"p"},"1"),"\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u6700\u540e\u70b9\u51fb ",(0,o.kt)("inlineCode",{parentName:"p"},"\u521b\u5efa"),"\uff0c\u542f\u52a8API\u63a8\u7406\u670d\u52a1\uff0c\u7b49\u5f852-3\u5206\u949fapi\u670d\u52a1\u5b8c\u6210\u542f\u52a8\uff1b"))),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"infernce_api_create",src:n(5491).Z,width:"2986",height:"1426"})),(0,o.kt)("h2",{id:"3-\u6d4b\u8bd5\u63a8\u7406api"},"3. \u6d4b\u8bd5\u63a8\u7406API"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u5f85API\u521b\u5efa\u5b8c\u6210\u540e\uff0c\u4ece\u9875\u9762\u83b7",(0,o.kt)("inlineCode",{parentName:"p"},"API URL"),"\uff0c\u5982 ",(0,o.kt)("inlineCode",{parentName:"p"},"http://inference-api-77.colossal-ai.platform.luchentech.com"),"\uff1b")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"\u5411\u6b64",(0,o.kt)("inlineCode",{parentName:"p"},"API URL"),"\u53d1\u9001\u5982\u4e0b\u793a\u4f8b\u8bf7\u6c42\uff0c\u6ce8\u610furl\u5e94\u653e\u7f6e\u524d\u4e00\u6b65\u83b7\u53d6\u7684",(0,o.kt)("inlineCode",{parentName:"p"},"API URL")))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker pull nvcr.io/nvidia/tritonserver:24.01-py3-sdk\ndocker run -it --rm --net=host nvcr.io/nvidia/tritonserver:24.01-py3-sdk\n\n/workspace/install/bin/image_client -url http://inference-api-77.colossal-ai.platform.luchentech.com -m densenet_tensorrt -c 3 -s INCEPTION /workspace/images/mug.jpg\n")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"\u6216\u8005\u4e5f\u53ef\u4ee5\u4f7f\u7528 python client \u53d1\u9001\u8bf7\u6c42\uff1a")),(0,o.kt)("p",null,"\u5b89\u88c5\u76f8\u5173python\u73af\u5883"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'wget  -O img1.jpg "https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg"\npip install torchvision\npip install attrdict\npip install nvidia-pyindex\npip install tritonclient[all]\n')),(0,o.kt)("p",null,"\u8fd0\u884c\u4e0b\u65b9python\u811a\u672c"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import numpy as np\nfrom torchvision import transforms\nfrom PIL import Image\nimport tritonclient.http as httpclient\nfrom tritonclient.utils import triton_to_np_dtype\n\ndef dn50_preprocess(img_path="img1.jpg"):\n    img = Image.open(img_path)\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    return preprocess(img).numpy()\n\ntransformed_img = dn50_preprocess()\n\n# Setup a connection with the Triton Inference Server.\ntriton_client = httpclient.InferenceServerClient(url="http://inference-api-77.colossal-ai.platform.luchentech.com")\n\n# Specify the names of the input and output layer(s) of our model.\ntest_input = httpclient.InferInput("input", transformed_img.shape, datatype="FP32")\ntest_input.set_data_from_numpy(transformed_img, binary_data=True)\n\ntest_output = httpclient.InferRequestedOutput("output", binary_data=True, class_count=1000)\n\n# Querying the server\nresults = triton_client.infer(model_name="densenet_tensorrt", inputs=[test_input], outputs=[test_output])\ntest_output_fin = results.as_numpy(\'output\')\n\nprint(test_output_fin[:5])\n\n')),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"API \u670d\u52a1\u5668\u4f1a\u5904\u7406\u8bf7\u6c42\uff0c \u5e76\u8fd4\u56de\u5982\u4e0b\u683c\u5f0f\u7684\u7ed3\u679c\uff1a")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"Request 0, batch size 1\nImage '/workspace/images/mug.jpg':\n    15.346230 (504) = COFFEE MUG\n    13.224326 (968) = CUP\n    10.422965 (505) = COFFEEPOT\n")))}u.isMDXComponent=!0},5491:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/infernce_api_create-7c89bc96b603d2cb9a527a776f41817a.jpg"}}]);